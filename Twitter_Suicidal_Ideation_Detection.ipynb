{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMIwTiOwiGK5"
   },
   "source": [
    "# **Import librares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bU21R8TAR0x",
    "outputId": "5a491785-360e-4b1a-ec17-6f643a63cf53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in c:\\program files\\python38\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\python38\\lib\\site-packages (from Keras-Preprocessing) (1.24.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\python38\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nltk/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\program files\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python38\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.16-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 20.5/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 406.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.6 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\program files\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.5 MB 210.4 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 349.3 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 430.1 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.5 MB 468.0 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.5 MB 468.0 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.5 MB 468.0 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.5 MB 468.0 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.3/1.5 MB 450.6 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 501.1 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 501.1 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 501.1 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 501.1 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 433.4 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 0.5/1.5 MB 508.6 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.6/1.5 MB 503.4 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 531.5 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.7/1.5 MB 544.8 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 679.4 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 703.5 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 703.5 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 703.5 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 655.4 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 689.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.5 MB 820.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 815.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 894.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 897.4 kB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp38-cp38-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/268.9 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 245.8/268.9 kB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 245.8/268.9 kB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 245.8/268.9 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.9/268.9 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.4.16 tqdm-4.66.2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpTokenizer\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing\n",
    "!pip install nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from textblob import Word\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Activation, Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten, GRU, Conv1D, MaxPooling1D, Bidirectional\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests\n",
    "from keras.regularizers import l2\n",
    "!pip install ktrain\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('brown')\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCpxu4ePiQqX"
   },
   "source": [
    "### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "bN-oDIKwosrZ",
    "outputId": "133375a1-8f38-4447-a39d-be701937fb61"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Twitter_Suicide_Dataset.csv\", engine='python', encoding='UTF-8')\n",
    "df=df.replace('Potential Suicide post ','Potential Suicide post')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhHsQRlsh-LH"
   },
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BxOOS9lOv5K",
    "outputId": "3fedf774-3ae1-41c4-be2f-29820b57f481"
   },
   "outputs": [],
   "source": [
    "df['Tweet']=df['Tweet'].fillna(\"\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLdDEYZmh5Ix"
   },
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WiypLl3PksF"
   },
   "outputs": [],
   "source": [
    "#Convert to lower case\n",
    "df['lower_case']= df['Tweet'].apply(lambda x: x.lower())\n",
    "#Tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['Special_word'] = df.apply(lambda row: tokenizer.tokenize(row['lower_case']), axis=1)\n",
    "#Stop words remove\n",
    "stop = stopwords.words('english')\n",
    "stop.remove(\"not\")\n",
    "stop.remove(\"here\")\n",
    "stop.remove(\"some\")\n",
    "df['stop_words'] = df['Special_word'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['stop_words'] = df['stop_words'].astype('str')\n",
    "#Filter words based on length\n",
    "df['short_word'] = df['stop_words'].str.findall('\\w{3,}')\n",
    "df['string']=df['short_word'].str.join(' ')\n",
    "#Removing non-english words(mention,emoji,link,special characters etc..)\n",
    "words = set(nltk.corpus.words.words())\n",
    "for w in reuters.words():\n",
    "  words.add(w)\n",
    "for w in brown.words():\n",
    "  words.add(w)\n",
    "for w in gutenberg.words():\n",
    "  words.add(w)\n",
    "df['NonEnglish'] = df['string'].apply(lambda x: \" \".join(x for x in x.split() if x in words))\n",
    "#Lemmatization\n",
    "df['tweet'] = df['NonEnglish'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "_DjgYNp5Cshr",
    "outputId": "766f260b-05d6-435b-cfab-71b297f1f882"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQoTgqU6V7GR"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "MIXeZI92JCvv",
    "outputId": "e48e641d-d34f-4f9a-ba46-845c20f1f7d9"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,7))\n",
    "df['length'] = df.tweet.str.split().apply(len)\n",
    "ax1 = fig.add_subplot(122)\n",
    "sns.histplot(df['length'], ax=ax1,color='green')\n",
    "describe = df.length.describe().to_frame().round(2)\n",
    "\n",
    "ax2 = fig.add_subplot(121)\n",
    "ax2.axis('off')\n",
    "font_size = 14\n",
    "bbox = [0, 0, 1, 1]\n",
    "table = ax2.table(cellText = describe.values, rowLabels = describe.index, bbox=bbox, colLabels=describe.columns)\n",
    "table.set_fontsize(font_size)\n",
    "fig.suptitle('Distribution of text length for positive sentiment tweets.', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "pSap9yxeXBHD",
    "outputId": "5c20d197-a6a2-4e94-b4df-313a4967d217"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.countplot(x=df[\"Suicide\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "2R4s7h54WgNs",
    "outputId": "d7190381-d04f-4366-9775-acb00ef0de74"
   },
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in df['short_word'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h',\n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk7NkbAXYx9X"
   },
   "outputs": [],
   "source": [
    "Not_Suicide_post = df[df['Suicide']=='Not Suicide post']\n",
    "Potential_Suicide_post = df[df['Suicide']=='Potential Suicide post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "ZXjf3F1hYylL",
    "outputId": "610c666b-a8ef-4300-9863-82f83ba9b5db"
   },
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in Not_Suicide_post['short_word'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Words in Not_Suicide_Post', orientation='h',\n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "uOohz8ceXzbt",
    "outputId": "cff01d27-9384-4e0f-a22a-51f499072596"
   },
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in Potential_Suicide_post['short_word'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Words in Potential_Suicide_post', orientation='h',\n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "4Y9ABIVQe-yr",
    "outputId": "f9e6c922-9a06-4052-fcbc-fcfbfcfafe11"
   },
   "outputs": [],
   "source": [
    "normal_words =' '.join([text for text in df['tweet']])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "aXGeJQRCe-vT",
    "outputId": "e50c8c2a-4e2c-4c64-e318-37311cd5bbc8"
   },
   "outputs": [],
   "source": [
    "normal_words =' '.join([text for text in df['tweet'][df['Suicide'] == 'Not Suicide post']])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "VTMfem9re-sE",
    "outputId": "ede80ebb-7871-42e5-9861-1dcba42b2963"
   },
   "outputs": [],
   "source": [
    "normal_words =' '.join([text for text in df['tweet'][df['Suicide'] == 'Potential Suicide post']])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JcF2V6whUsp"
   },
   "source": [
    "## **Applying N-gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F95WTCewWV45",
    "outputId": "0b0fce5b-edff-40ca-d104-791d19296282"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[\"tweet\"],df[\"Suicide\"], test_size = 0.25, random_state = 42)\n",
    "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
    "\n",
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "\n",
    "print (x_train_tfidf.shape,x_test_tfidf.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BKmHtSuZxmv"
   },
   "source": [
    "# **Deep Learning Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCLriPu0Z0yI",
    "outputId": "10f7e560-27b1-42bd-de02-09eef316b5e5"
   },
   "outputs": [],
   "source": [
    "vocabulary_size =6000\n",
    "max_text_len = 60\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['Tweet'].values)\n",
    "le=len(tokenizer.word_index)+1\n",
    "print(le)\n",
    "sequences = tokenizer.texts_to_sequences(df['Tweet'].values)\n",
    "X_DeepLearning = pad_sequences(sequences, maxlen=max_text_len)\n",
    "X_DeepLearning.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSW60ZSAdPDY"
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer object\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSbFRu2VazjK",
    "outputId": "6ee3f4ff-573f-4979-90c6-eb0e371d3db6"
   },
   "outputs": [],
   "source": [
    "df.loc[df['Suicide'] == 'Potential Suicide post' , 'LABEL'] = 0\n",
    "df.loc[df['Suicide'] == 'Not Suicide post', 'LABEL'] = 1\n",
    "\n",
    "labels = to_categorical(df['LABEL'], num_classes=2)\n",
    "print(labels[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GQORt5zcHBg",
    "outputId": "9f0b3eda-8729-4050-a999-f5d07d631fec"
   },
   "outputs": [],
   "source": [
    "XX_train, XX_test, y_train, y_test = train_test_split(X_DeepLearning , labels, test_size=0.25, random_state=42)\n",
    "print((XX_train.shape, y_train.shape, XX_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMnjZCZ9Ei3"
   },
   "source": [
    "# **LSTM 1-Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWOrNwzBcHK7",
    "outputId": "f97b7ba2-8357-4b58-953c-4fc5fe57c8bf"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 120\n",
    "batch_size = 50\n",
    "model_lstm1 = Sequential()\n",
    "model_lstm1.add(Embedding(vocabulary_size,emb_dim, input_length=X_DeepLearning.shape[1]))\n",
    "model_lstm1.add(SpatialDropout1D(0.8))\n",
    "model_lstm1.add(Bidirectional(LSTM(300, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model_lstm1.add(Dropout(0.5))\n",
    "model_lstm1.add(Flatten())\n",
    "model_lstm1.add(Dense(64, activation='relu'))\n",
    "model_lstm1.add(Dropout(0.5))\n",
    "model_lstm1.add(Dense(2, activation='softmax'))\n",
    "model_lstm1.compile(optimizer=tf.optimizers.Adam(),loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_lstm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jd9fzl82nnnx"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath=\"lastm-1-layer-best_model.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5X0-hmhekRvG",
    "outputId": "09de2455-9f2a-497f-95a9-c28e7cb5f5d6"
   },
   "outputs": [],
   "source": [
    "history_lstm1 = model_lstm1.fit(XX_train, y_train, epochs = epochs, batch_size = batch_size, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZK0thHrkJzr",
    "outputId": "f025ebe8-eccf-4ae6-d034-c0c6cfdbc281"
   },
   "outputs": [],
   "source": [
    "results_1 = model_lstm1.evaluate(XX_test, y_test, verbose=False)\n",
    "print(f'Test results - Loss: {results_1[0]} - Accuracy: {100*results_1[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "wKKkYBW7gRcs",
    "outputId": "19d188b3-d201-4aa5-96fa-160f03cb3aed"
   },
   "outputs": [],
   "source": [
    "acc = history_lstm1.history['acc']\n",
    "val_acc = history_lstm1.history['val_acc']\n",
    "loss = history_lstm1.history['loss']\n",
    "val_loss = history_lstm1.history['val_loss']\n",
    "plt.plot( acc, 'go', label='Train accuracy')\n",
    "plt.plot( val_acc, 'g', label='Validate accuracy')\n",
    "plt.title('Train and validate accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( loss, 'go', label='Train loss')\n",
    "plt.plot( val_loss, 'g', label='Validate loss')\n",
    "plt.title('Train and validate loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GHsW2cT6OZX",
    "outputId": "da78720f-3787-4e89-fe84-ee1ba6a0ab6c"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer object\n",
    "with open('/content/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "model = load_model('/content/lastm-1-layer-best_model.h5')\n",
    "#model.save('/content/drive/MyDrive/Colab_Notebooks/DL Model/Twitter Suicide Ideation Detection/lstm 1-layer.h5')\n",
    "\n",
    "twt = ['i will not kill myself ']\n",
    "twt = tokenizers.texts_to_sequences(twt)\n",
    "twt = pad_sequences(twt, maxlen=60, dtype='int32')\n",
    "\n",
    "predicted = model.predict(twt,batch_size=1,verbose = True)\n",
    "if(np.argmax(predicted) == 0):\n",
    "    print(\"Potential Suicide Post\")\n",
    "elif (np.argmax(predicted) == 1):\n",
    "    print(\"Non Suicide Post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preniFcl9Tqn"
   },
   "source": [
    "## **LSTM 2-Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nj2aOnLgRmx",
    "outputId": "5fcfa420-d29b-47a4-85b4-d8dd223cd709"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 120\n",
    "batch_size = 50\n",
    "model_lstm2 = Sequential()\n",
    "model_lstm2.add(Embedding(vocabulary_size,emb_dim ,input_length=X_DeepLearning.shape[1]))\n",
    "model_lstm2.add(SpatialDropout1D(0.8))\n",
    "model_lstm2.add(Bidirectional(LSTM(200, dropout=0.5, recurrent_dropout=0.5, return_sequences= True)))\n",
    "model_lstm2.add(Dropout(0.5))\n",
    "model_lstm2.add(Bidirectional(LSTM(300, dropout=0.5, recurrent_dropout =0.5)))\n",
    "model_lstm2.add(Dropout(0.5))\n",
    "model_lstm2.add(Flatten())\n",
    "model_lstm2.add(Dense(64, activation='relu'))\n",
    "model_lstm2.add(Dropout(0.5))\n",
    "model_lstm2.add(Dense(2, activation='softmax'))\n",
    "model_lstm2.compile(optimizer=tf.optimizers.Adam(),loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_lstm2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JD5IIllnuk-J"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath=\"lastm-2-layer-best_model.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks2=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i41SW8PCubry",
    "outputId": "c580c258-41a4-4abb-9c61-318d912e4547"
   },
   "outputs": [],
   "source": [
    "history_lstm2 = model_lstm2.fit(XX_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=callbacks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gZRYbaUuecG",
    "outputId": "fa797165-cf71-44ac-8520-843604da0e52"
   },
   "outputs": [],
   "source": [
    "results_2 = model_lstm2.evaluate(XX_test, y_test, verbose=False)\n",
    "print(f'Test results - Loss: {results_2[0]} - Accuracy: {100*results_2[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "iG-B1O4RhwW5",
    "outputId": "f16de663-a69c-49fa-86e4-b857439a8d19"
   },
   "outputs": [],
   "source": [
    "acc = history_lstm2.history['acc']\n",
    "val_acc = history_lstm2.history['val_acc']\n",
    "loss = history_lstm2.history['loss']\n",
    "val_loss = history_lstm2.history['val_loss']\n",
    "\n",
    "plt.plot( acc, 'go', label='Train accuracy')\n",
    "plt.plot( val_acc, 'g', label='Validate accuracy')\n",
    "plt.title('Train and validate accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot( loss, 'go', label='Train loss')\n",
    "plt.plot( val_loss, 'g', label='Validate loss')\n",
    "plt.title('Train and validate loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbKUYrQ_QsWs",
    "outputId": "3e4ca1d2-5d16-4aae-802e-d01190ecbb33"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer object\n",
    "with open('/content/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "model = load_model('/content/lastm-2-layer-best_model.h5')\n",
    "#model.save('/content/drive/MyDrive/Colab_Notebooks/DL Model/Twitter Suicide Ideation Detection/lstm 2-layer.h5')\n",
    "\n",
    "twt = [\"i will not kill myself. \"]\n",
    "twt = tokenizers.texts_to_sequences(twt)\n",
    "twt = pad_sequences(twt, maxlen=60, dtype='int32')\n",
    "\n",
    "predicted = model.predict(twt,batch_size=1,verbose = True)\n",
    "if(np.argmax(predicted) == 0):\n",
    "    print(\"Potential Suicide Post\")\n",
    "elif (np.argmax(predicted) == 1):\n",
    "    print(\"Non Suicide Post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmKLJz0g9h59"
   },
   "source": [
    "## **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBaaAOlZwaoG",
    "outputId": "ee4ca823-f11e-4276-8e4c-66b0b06bc63b"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 120\n",
    "batch_size = 50\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(vocabulary_size,emb_dim ,input_length=X_DeepLearning.shape[1]))\n",
    "model_gru.add(SpatialDropout1D(0.5))\n",
    "model_gru.add(GRU(units=16,  dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01)))\n",
    "model_gru.add(Dropout(0.5))\n",
    "model_gru.add(Dense(228, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_gru.add(Dropout(0.5))\n",
    "model_gru.add(Dense(2, activation='softmax'))\n",
    "model_gru.compile(optimizer=tf.optimizers.Adam(),loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57SZmAD1IMHq"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath=\"gru-best_model.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks3=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dULkpPwITms",
    "outputId": "d7231cdb-40e2-45c8-9eb0-9e8b50dd0a3f"
   },
   "outputs": [],
   "source": [
    "history_gru = model_gru.fit(XX_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1, callbacks=callbacks3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WheIwrNIisS",
    "outputId": "a847d7e9-26fe-4420-a0e7-087e7736ec59"
   },
   "outputs": [],
   "source": [
    "results_3 = model_gru.evaluate(XX_test, y_test, verbose=False)\n",
    "print(f'Test results - Loss: {results_3[0]} - Accuracy: {100*results_3[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "ryRFZM54wZ-V",
    "outputId": "a39718a2-6f0a-4a36-e1f8-1edcdf456e30"
   },
   "outputs": [],
   "source": [
    "acc = history_gru.history['acc']\n",
    "val_acc = history_gru.history['val_acc']\n",
    "loss = history_gru.history['loss']\n",
    "val_loss = history_gru.history['val_loss']\n",
    "\n",
    "plt.plot( acc, 'go', label='Train accuracy')\n",
    "plt.plot( val_acc, 'g', label='Validate accuracy')\n",
    "plt.title('Train and validate accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot( loss, 'go', label='Train loss')\n",
    "plt.plot( val_loss, 'g', label='Validate loss')\n",
    "plt.title('Train and validate loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUztgTb7Rskq",
    "outputId": "c66877e2-22a2-4739-bb24-e958e07be30e"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer object\n",
    "with open('/content/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "model = load_model('/content/gru-best_model.h5')\n",
    "#model.save('/content/drive/MyDrive/Colab_Notebooks/DL Model/Twitter Suicide Ideation Detection/gru-best_model.h5')\n",
    "\n",
    "twt = [\"i will not kill myself.\"]\n",
    "twt = tokenizers.texts_to_sequences(twt)\n",
    "twt = pad_sequences(twt, maxlen=60, dtype='int32')\n",
    "\n",
    "predicted = model.predict(twt,batch_size=1,verbose = True)\n",
    "if(np.argmax(predicted) == 0):\n",
    "    print(\"Potential Suicide Post\")\n",
    "elif (np.argmax(predicted) == 1):\n",
    "    print(\"Non Suicide Post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCutiIvS91Ak"
   },
   "source": [
    "## **CNN+LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlkGwCfGhwgQ",
    "outputId": "3a75870b-f950-40a5-c5d3-de42f61003a9"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 120\n",
    "batch_size = 50\n",
    "model_cl = Sequential()\n",
    "model_cl.add(Embedding(vocabulary_size,emb_dim, input_length=X_DeepLearning.shape[1]))\n",
    "model_cl.add(SpatialDropout1D(0.8))\n",
    "model_cl.add(Conv1D(filters=64, kernel_size=6, padding='same', activation='relu'))\n",
    "model_cl.add(MaxPooling1D(pool_size=2))\n",
    "model_cl.add(Conv1D(filters=32, kernel_size=6, activation='relu'))\n",
    "model_cl.add(MaxPooling1D(pool_size=2))\n",
    "model_cl.add(Bidirectional(LSTM(100, dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))\n",
    "model_cl.add(Dropout(0.5))\n",
    "model_cl.add(Bidirectional(LSTM(400, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model_cl.add(Dropout(0.5))\n",
    "model_cl.add(Flatten())\n",
    "model_cl.add(Dense(64, activation='relu'))\n",
    "model_cl.add(Dropout(0.5))\n",
    "model_cl.add(Dense(2, activation='softmax'))\n",
    "model_cl.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_cl.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DrFIekFHhH4"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath=\"cnn+lastm-best_model.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlg5vAF1HrIp",
    "outputId": "7b8af468-32ba-457c-b19b-2958e4b00ad9"
   },
   "outputs": [],
   "source": [
    "history_cl = model_cl.fit(XX_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSinpiEgHyOF",
    "outputId": "75fb9edf-f88e-4688-cd1d-c0581ef13d39"
   },
   "outputs": [],
   "source": [
    "results_4 = model_cl.evaluate(XX_test, y_test, verbose=False)\n",
    "print(f'Test results - Loss: {results_4[0]} - Accuracy: {100*results_4[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "_54CKPvIpoAC",
    "outputId": "ea479553-7c9b-4511-8363-2c39ac77f856"
   },
   "outputs": [],
   "source": [
    "acc = history_cl.history['acc']\n",
    "val_acc = history_cl.history['val_acc']\n",
    "loss = history_cl.history['loss']\n",
    "val_loss = history_cl.history['val_loss']\n",
    "plt.plot( acc, 'go', label='Train accuracy')\n",
    "plt.plot( val_acc, 'g', label='Validate accuracy')\n",
    "plt.title('Train and validate accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( loss, 'go', label='Train loss')\n",
    "plt.plot( val_loss, 'g', label='Validate loss')\n",
    "plt.title('Train and validate loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iI5rMYR3YMBi",
    "outputId": "b6b23964-d686-484e-b7ad-3efaab632be4"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer object\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizers = pickle.load(handle)\n",
    "\n",
    "model = load_model('/content/cnn+lastm-best_model.h5')\n",
    "model_cl.save('/content/drive/MyDrive/Colab_Notebooks/DL Model/Twitter Suicide Ideation Detection/CNN+LSTM.h5')\n",
    "\n",
    "twt = ['I will not kill myself']\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "twt = pad_sequences(twt, maxlen=60, dtype='int32')\n",
    "\n",
    "predicted = model.predict(twt,batch_size=1,verbose = True)\n",
    "if(np.argmax(predicted) == 0):\n",
    "    print(\"Potential Suicide Post\")\n",
    "elif (np.argmax(predicted) == 1):\n",
    "    print(\"Non Suicide Post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds7KNJfH9_c0"
   },
   "source": [
    "## **Model Comparision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iR4-E57Hfqfl",
    "outputId": "065b0255-b7e2-4fd2-8d04-f38da5895796"
   },
   "outputs": [],
   "source": [
    "results=pd.DataFrame({'Model':['LSTM-1 Layer','LSTM-2 Layer','GRU','CNN+LSTM'],\n",
    "                     'Accuracy Score':[results_1[1],results_2[1],results_3[1],results_4[1]]})\n",
    "result_df=results.sort_values(by='Accuracy Score', ascending=False)\n",
    "result_df=result_df.set_index('Model')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORhBqVHxhjq7"
   },
   "source": [
    "## **Bert Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5Q324QYROUt"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweet'], df['Suicide'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbejVw-eROuq"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CX33KojOROr8"
   },
   "outputs": [],
   "source": [
    "class_names = ['Potential Suicide post', 'Not Suicide post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "9V9v3o8AXXnz",
    "outputId": "18863751-792f-4c12-85a8-24b92f5bb1e0"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_val,y_val), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
    "                                                                       x_test=X_test, y_test=y_test,\n",
    "                                                                       class_names=class_names,\n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       maxlen=140,\n",
    "                                                                       max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mB9Skxe8XYIN",
    "outputId": "541b9020-e86e-4d77-b83f-2f133e98c16d"
   },
   "outputs": [],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train,y_train), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CQC_vCSXYgT"
   },
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=(x_train,y_train),\n",
    "                             val_data=(x_val,y_val),\n",
    "                             batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXmKRqHfYJjN",
    "outputId": "f7b9810f-7ea1-49ff-a3cd-e0436ffc5eb1"
   },
   "outputs": [],
   "source": [
    "learner.fit_onecycle(2e-5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "O1FgwHVL2i_j",
    "outputId": "3530acac-a881-4229-902c-a7d6fae5fd6d"
   },
   "outputs": [],
   "source": [
    "learner.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-xDAUzuYJfS",
    "outputId": "14cdcec9-9217-4ef6-be69-efce177c0cfd"
   },
   "outputs": [],
   "source": [
    "learner.validate(val_data=(x_val,y_val), class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCspUnWbvFWr",
    "outputId": "a328d057-e347-4c7c-dd84-f762686b2ef0"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4POGXDtIvTe8",
    "outputId": "c714b95b-5a5f-469e-bf3d-edd53c84ae46"
   },
   "outputs": [],
   "source": [
    "message = 'i will not kill myself'\n",
    "prediction = predictor.predict(message)\n",
    "print('predicted: {}'.format(prediction))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
